{"cells":[{"cell_type":"code","execution_count":30,"metadata":{"id":"snQCxxteB1xK","executionInfo":{"status":"ok","timestamp":1661170720246,"user_tz":-330,"elapsed":481,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"}}},"outputs":[],"source":["import torch\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"YQNwOjuACSYw","executionInfo":{"status":"ok","timestamp":1661170720894,"user_tz":-330,"elapsed":6,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"}}},"outputs":[],"source":["\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","\n","else:\n","  device = torch.device(\"cpu\")\n"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3493,"status":"ok","timestamp":1661170724382,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"},"user_tz":-330},"id":"8bga6Kg-CGIM","outputId":"c86da3ed-41ad-4c80-f850-d0103f48cb1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","train_Data = pd.read_csv(\"/content/drive/MyDrive/Urdu_hate/train_set_taskA - train_set_Fire2022.csv\")\n","\n"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1661170724383,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"},"user_tz":-330},"id":"P2783yV1Cr_K","outputId":"dcd7f192-054a-4eef-9ee2-7c614d5fcf81"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      anger  disgust  fear  sadness  surprise  happiness  neutral  \\\n","0         0        0     0        1         1          0        0   \n","1         0        0     0        0         0          1        0   \n","2         0        0     0        0         0          0        1   \n","3         0        0     0        0         0          0        1   \n","4         0        0     0        0         0          0        1   \n","...     ...      ...   ...      ...       ...        ...      ...   \n","7795      0        0     0        0         0          0        1   \n","7796      0        0     0        0         0          0        1   \n","7797      0        0     0        0         0          1        0   \n","7798      0        0     1        0         0          0        0   \n","7799      0        0     0        0         0          0        1   \n","\n","                                              Sentences  \n","0                        محبت کے پردے میں نفرت کرنےوالو  \n","1     حامد میر کی خوشی کے لئے اس کا ذمہ دار حکومت ہو...  \n","2     اس نئے سال کی شام، ایک سپاہی قاتل (لارنس Fishb...  \n","3     کچھ اس طرح سے ایک فلم کے لئے جا سکتے ہیں لیکن ...  \n","4     رون ہاورڈ اور اس کے \"ایڈیٹرز\" صرف اتنا کرنا .....  \n","...                                                 ...  \n","7795  آپ کس طرح نوجوان برطانوی اداکار کی اس قابل احت...  \n","7796  میں نے امریکہ کے کنفیڈریشن امریکہ میں ورجینیا ...  \n","7797  سورۃ نمبر النساء آیت نمبر جب تم سفر پر جا رہے ...  \n","7798  رونا یہ نہیں کہ حالات خراب ہیں اوراس بیماری نے...  \n","7799  میں ایک لڑکا (دوسری جنگ عظیم سے پہلے) تھا جب م...  \n","\n","[7800 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-540e2e4f-2ab2-44a5-b3af-d29db15ffe47\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>anger</th>\n","      <th>disgust</th>\n","      <th>fear</th>\n","      <th>sadness</th>\n","      <th>surprise</th>\n","      <th>happiness</th>\n","      <th>neutral</th>\n","      <th>Sentences</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>محبت کے پردے میں نفرت کرنےوالو</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>حامد میر کی خوشی کے لئے اس کا ذمہ دار حکومت ہو...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>اس نئے سال کی شام، ایک سپاہی قاتل (لارنس Fishb...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>کچھ اس طرح سے ایک فلم کے لئے جا سکتے ہیں لیکن ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>رون ہاورڈ اور اس کے \"ایڈیٹرز\" صرف اتنا کرنا .....</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7795</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>آپ کس طرح نوجوان برطانوی اداکار کی اس قابل احت...</td>\n","    </tr>\n","    <tr>\n","      <th>7796</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>میں نے امریکہ کے کنفیڈریشن امریکہ میں ورجینیا ...</td>\n","    </tr>\n","    <tr>\n","      <th>7797</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>سورۃ نمبر النساء آیت نمبر جب تم سفر پر جا رہے ...</td>\n","    </tr>\n","    <tr>\n","      <th>7798</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>رونا یہ نہیں کہ حالات خراب ہیں اوراس بیماری نے...</td>\n","    </tr>\n","    <tr>\n","      <th>7799</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>میں ایک لڑکا (دوسری جنگ عظیم سے پہلے) تھا جب م...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7800 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-540e2e4f-2ab2-44a5-b3af-d29db15ffe47')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-540e2e4f-2ab2-44a5-b3af-d29db15ffe47 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-540e2e4f-2ab2-44a5-b3af-d29db15ffe47');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":33}],"source":["train_Data"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"kGAU69IYDhOD","executionInfo":{"status":"ok","timestamp":1661170724384,"user_tz":-330,"elapsed":34,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"}}},"outputs":[],"source":["X_train = np.array(train_Data['Sentences'])\n","y_train_arr = np.array(train_Data.drop(['Sentences'],axis = 1),dtype = np.float64)\n","\n","\n"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1661170724385,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"},"user_tz":-330},"id":"Z94l3V-QET_j","outputId":"e82a8b4c-9c30-4c2b-95f6-c2666b17888a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., ..., 1., 0., 0.],\n","       [0., 0., 0., ..., 0., 1., 0.],\n","       [0., 0., 0., ..., 0., 0., 1.],\n","       ...,\n","       [0., 0., 0., ..., 0., 1., 0.],\n","       [0., 0., 1., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 1.]])"]},"metadata":{},"execution_count":35}],"source":["y_train_arr"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1661170724386,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"},"user_tz":-330},"id":"yTJ7WQFkEYVZ","outputId":"e6628d95-9067-42e0-b9ed-5e74741f6c0b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['محبت کے پردے میں نفرت کرنےوالو',\n","       'حامد میر کی خوشی کے لئے اس کا ذمہ دار حکومت ہو گی خوش',\n","       'اس نئے سال کی شام، ایک سپاہی قاتل (لارنس Fishburne، کی شکل میں) ایک شعبے برف تک وجہ سے بند کر رہا ہے کہ میں ختم ہے. لوگوں پر محاصرے layed رہے ہیں، پولیس کو زندہ رہنے کے لئے cons کے ساتھ ٹیم کے لئے ہے. جان بڑھئ کلاسک کا یہ دوبارہ بنانے بس نہیں، بیوکوف پلاٹ twists پرے چند شامل تمام کشیدگی باہر لے، اور کاسٹ کرنے کے لئے ایک بینکر جان Lequizamo شامل کرنے کے لئے تھا جو کیا تھا؟ پہلی فلم سنسنی خیز، کرکرا، اور دیکھنے کے لئے ایک خوشی تھی. یہ ایک اور ہالی ووڈ، آہنی اور دیکھ کرنے کے لئے تکلیف دہ ہے. میں نے اس فلم سے لیا صرف ایک ہی چیز OCD بہت پریشان کن ہو سکتا ہے ... بہت تھا. ختم ہونے والے گیت SOOOOOOOOOOOOOOOOO برا ہے <br /> <br /> میری گریڈ: D- <br /> <br /> DVD ایکسٹراز: Richet، Demonaco اور جیفری سلور کی شروحات؛ اختیاری تفسیر کے ساتھ خارج مناظر؛ 5 منٹ \"مسلح اور خطرناک\" ہتھیاروں کے ماہر پر featurette کے؛ 7 اور ڈیڑھ منٹ \"شعبے دیواروں کے پیچھے\"؛ \"حملہ کی منصوبہ بندی\"؛ \"حملہ ٹیم\"؛ 12 اور پردے کے پیچھے ڈیڑھ منٹ کے لئے ٹریلرز featurette کے ؛، \"ہوا\"، \"وائٹ شور\"،: Chucky کے \"بیج <br /> <br /> Miscelanious: میں بہترین خریدیں یہ ملا اور یہ ایک بونس ڈسک کے ساتھ آئے سمیت کے \"رونا ولف\" پہلے 2 منٹ؛ \"ہوا\" پر ایک 10 منٹ پہلے نظر؛ کہ فلم کے ٹریلر؛ اور جان Leguizamo ساتھ ایک Fuzion انٹرویو',\n","       ...,\n","       'سورۃ نمبر النساء آیت نمبر جب تم سفر پر جا رہے ہو تو تم پر نمازوں کے قصر کرنے میں کوئی گناہ نہیں اگر تمہیں ڈ',\n","       'رونا یہ نہیں کہ حالات خراب ہیں اوراس بیماری نے انہیں مخدوش کردیاہے ڈر اس بات کا ہے کہ وبا اوراُس کے اثرات میں کمی',\n","       'میں ایک لڑکا (دوسری جنگ عظیم سے پہلے) تھا جب میں نے یہ فلم دیکھی تھی اور تعجب کیا گیا تھا مقامی لائبریری ایک کاپی تھی. کوئی ساٹھ سال کے بعد ایک بار پھر اسے دیکھا اور یہ کتنا برا تھا بھول گیا. یہ ہے کہ ایک \"A\" فلم نہیں تھا ایک فلم کی ایک مثال ہے. کوئی ترمیم، غریب سکرپٹ، کمزور اداکاری اور نہ زیادہ ہدایت کی ہے. یہاں تک کہ ایک \"B\" میں سال کے دوران بن گیا ہوں میں jaded کس طرح پر ایک ہنسی تھا کے طور پر اعلی کے طور پر نہیں کیا جانا چاہئے. مجھے لگتا ہے میں نے یہ اچھا تھا کہ میں نے اصل میں یہ دیکھ کر سوچا.'],\n","      dtype=object)"]},"metadata":{},"execution_count":36}],"source":["X_train"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"5zNIz8RfEbZl","executionInfo":{"status":"ok","timestamp":1661170724387,"user_tz":-330,"elapsed":31,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"}}},"outputs":[],"source":["y_train = []\n","for arr in y_train_arr:\n","  val = 0 \n","  for i in range(7):\n","    if arr[i] == 1:\n","      val += 2**i\n","  y_train.append(val);\n","\n"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"GEwc5qDyF5pY","executionInfo":{"status":"ok","timestamp":1661170724387,"user_tz":-330,"elapsed":29,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"}}},"outputs":[],"source":["y_train = np.array(y_train,dtype = np.float64)"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1661170724387,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"},"user_tz":-330},"id":"4LoxYnSvGMCB","outputId":"a19b8ce3-819e-428b-f99f-ce536db60117"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([24., 32., 64., ..., 32.,  4., 64.])"]},"metadata":{},"execution_count":39}],"source":["y_train"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"jnBDqkVPGYBs","executionInfo":{"status":"ok","timestamp":1661170724388,"user_tz":-330,"elapsed":21,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"}}},"outputs":[],"source":["X_t , X_v , y_t,y_v  =  train_test_split(X_train,y_train,test_size = 0.15,random_state = 2020)"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1661170724389,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"},"user_tz":-330},"id":"SQy4zau-NZxy","outputId":"7502177c-a693-4047-d2fa-bbc80084cc92"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['یہ ہستا کھیلتا لڑکا کسی دن آہ بھر لے گا لکھا جائے گا تختی پر اُداسی کھا گئی اس کو',\n","       'ہو سکتا ہے کہ یہ اس کے 1997 میں بنایا گیا تھا صرف یہ ہے کہ، یا شاید ایک 7 اس کو حاصل کرنے کے لئے منظم جو ایڈز کے ساتھ بچوں کے لئے ایک نرم جگہ ہے ہے. لیکن واقعی لوگوں، واپسی منظر کے دوران maniacal کی ہنسی اور افراتفری؟ آپ اس آنے والے نہیں دیکھا؟ میں نے چھت کے پار اور کیمرے سے خطاب sickboy داخلے کا کوئی بچہ نہیں تھا حیران ہوں. اداکاری اس بات کا یقین ٹھیک تھا. لیکن میرے پاس اس کے حالات اور موضوع سنیما کی زبان کے لئے منتقل کر سکتے ہیں جب ایک وقت کی طرف سے ایک فلم کی صرف ایک مثال ہے. چیزیں ہوتی ہیں لیکن یہ بات ہے. کوئی گلو یا مقصد نفس مضمون پہلے سے موجود جذباتی کنکشن کے پلاٹ furthur کو استعمال کرنے کی اجازت دی ہے، سکرین پر پتہ لگایا جا سکتا ہے کہ جو کرنا ہے جیسے یہ کام کر رہے سکرپٹ کے بغیر، نہیں ہے.',\n","       '\"Incubus کی\" نیک (ایک دلچسپ قتل اسرار)، برا (ایک منقطع اسکرپٹ، ایک میلا قرارداد، بری طرح بنایا حملے کے مناظر) اور عجیب (مضبوط incestuous کو مفہوم، جان Cassavetes طرف سے ایک عجیب نیند اور سخت کارکردگی کا ایک مرکب ہے - اس کردار واقعی ایسا \"عجیب\" ہونا چاہیے تھا)؟. تقریبا نہیں جارحانہ طور پر اس کے لئے مشہور طور پر ہے، لیکن خاص طور پر کامیاب نہیں، یا تو. (* 1/2)',\n","       ...,\n","       'کمال ہے یہ تو مجھے بھی بلاک کر دیا اب چک کیا ہے حالانکہ بغیر کسی وجہ کہ جمیل فاروقی کو کس بات کا ڈر ہے جو پہلے',\n","       'کیوں نہ حیرت ہو کہ بغض و کینہ و رنج و ملالہم کو دشمن سے نہیں ہے تم کو جتنا ہم سے ہے داغ',\n","       'عمران خان کے چہرے پر جو خوشی اور سکون غریبوں کو پیسے بانٹنے کا اعلان کرتے ہوئے آتا ہے وہ دیدنی ہے کسی نے صیح کہا'],\n","      dtype=object)"]},"metadata":{},"execution_count":41}],"source":["X_t "]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3455,"status":"ok","timestamp":1661170727827,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"},"user_tz":-330},"id":"EnphF1FpRDUP","outputId":"e7500b1f-9239-47ae-c3d6-0a13d79d59e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":1836,"status":"ok","timestamp":1661170729657,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"},"user_tz":-330},"id":"sr4dFOBxMkkF"},"outputs":[],"source":["from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n","text = \" Hi my name is Anik \"\n","encodings = tokenizer.encode_plus(text, add_special_tokens = True,\n","                                  max_length=256,\n","                                  padding = 'max_length',\n","                                  truncation = True,\n","                                  return_attention_mask = True,\n","                                  return_tensors = 'pt')\n","\n","target_list = ['anger','disgust','fear','sadness','surprise','happiness','neutral']"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1661170729658,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"},"user_tz":-330},"id":"Y5w4e_eUireS","outputId":"a4340c19-e49b-4d3e-d265-1bd89f38209d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"]},"metadata":{},"execution_count":44}],"source":["encodings['token_type_ids']\n"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"IvAlO0sTT-l3","executionInfo":{"status":"ok","timestamp":1661170729659,"user_tz":-330,"elapsed":29,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"}}},"outputs":[],"source":["class CustomDataset(torch.utils.data.Dataset):\n","  def __init__(self,df,tokenizer,max_len):\n","    self.df = df;\n","    self.tokenizer = tokenizer\n","    self.max_len = max_len\n","    self.title = self.df['Sentences']\n","    self.targets = self.df[target_list].values\n","\n","  def __len__(self):\n","    return len(self.title)\n","\n","  def __getitem__(self,index):\n","    text = (self.title.iloc[index])\n","    \n","    text = \" \".join(text.split()) #return to this function \n","\n","    inputs = self.tokenizer.encode_plus(text,add_special_tokens = True,\n","                                  max_length=self.max_len,\n","                                  padding = 'max_length',\n","                                  return_token_type_ids = True,\n","                                  truncation = True,\n","                                  return_attention_mask = True,\n","                                  return_tensors = 'pt')\n","    \n","    return {\n","        'input_ids' : inputs['input_ids'].flatten(),\n","        'attention_mask' : inputs['attention_mask'].flatten(),\n","        'token_type_ids' : inputs['token_type_ids'].flatten(),\n","        'targets': torch.FloatTensor(self.targets[index])\n","    }\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"mH1FwOB2lmSB","executionInfo":{"status":"ok","timestamp":1661170729659,"user_tz":-330,"elapsed":28,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"}}},"outputs":[],"source":["train_df , val_df = train_test_split(train_Data,test_size = 0.2, random_state = 2020)\n","\n","X_train , X_val = train_test_split(train_Data['Sentences'] , test_size = 0.2,random_state = 2020)\n","y_df = pd.DataFrame(y_train , columns = ['Emotion'])\n","y_train , y_val = train_test_split(y_df , test_size = 0.2,random_state = 2020)\n","\n"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1661170729660,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"},"user_tz":-330},"id":"aqjFiHxDoNHa","outputId":"ce5cbede-984a-4d68-a126-234b736317ef"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6240, 1)"]},"metadata":{},"execution_count":47}],"source":["y_train.shape"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1661170729661,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"},"user_tz":-330},"id":"UakUgHr6oVDq","outputId":"da241ee5-bf51-4a54-ec32-de047d0f9c48"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1560, 1)"]},"metadata":{},"execution_count":48}],"source":["y_val.shape"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1661170729661,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"},"user_tz":-330},"id":"JQ59n1hhoX-n","outputId":"f766d1c1-132d-436a-e157-29e711de340d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      anger  disgust  fear  sadness  surprise  happiness  neutral\n","1489      0        0     0        0         0          0        1\n","133       0        0     0        0         0          1        0\n","643       0        0     0        0         0          0        1\n","5556      0        0     0        0         0          0        1\n","5881      0        0     1        0         0          0        0\n","...     ...      ...   ...      ...       ...        ...      ...\n","2783      1        1     0        0         0          0        0\n","5272      0        0     0        0         0          0        1\n","6808      0        0     0        0         0          0        1\n","5700      0        0     0        0         0          0        1\n","2106      0        0     1        0         0          0        0\n","\n","[3900 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-d8ce484f-f3d3-4f12-a625-6a18a8ca3164\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>anger</th>\n","      <th>disgust</th>\n","      <th>fear</th>\n","      <th>sadness</th>\n","      <th>surprise</th>\n","      <th>happiness</th>\n","      <th>neutral</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1489</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>133</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>643</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5556</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5881</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2783</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5272</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6808</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5700</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2106</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3900 rows × 7 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8ce484f-f3d3-4f12-a625-6a18a8ca3164')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d8ce484f-f3d3-4f12-a625-6a18a8ca3164 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d8ce484f-f3d3-4f12-a625-6a18a8ca3164');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":49}],"source":["X_train.shape\n","train_df[target_list]\n","val_df[target_list]"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1661170729662,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"},"user_tz":-330},"id":"c4wurnajobBW","outputId":"a8737f92-48ea-4997-f376-0ba614544569"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      anger  disgust  fear  sadness  surprise  happiness  neutral  \\\n","4071      0        0     0        0         0          1        0   \n","6073      0        0     0        1         1          0        0   \n","3260      0        0     0        0         0          0        1   \n","2589      1        1     0        0         0          0        0   \n","642       0        0     0        0         0          0        1   \n","...     ...      ...   ...      ...       ...        ...      ...   \n","3779      0        0     0        0         0          0        0   \n","6774      0        0     0        0         0          1        0   \n","7491      1        1     0        1         0          0        0   \n","4488      0        0     0        1         1          0        0   \n","864       0        0     0        0         1          1        0   \n","\n","                                              Sentences  \n","4071                    مینے سوچا بتادوں خوشی بانٹ دوں😂  \n","6073  میسر تجھے ہر خوشی ہوگی لیکن مجھے یاد کر کے تو ...  \n","3260  اقرار بریڈ پٹ کے بارے میں فنتاسیوں اندوز کرنے ...  \n","2589  اس کو کوئ ایک تکلیف ہو تو بتائیں حسد کی آگ میں...  \n","642   اس طرح ایک عظیم کتاب اس طرح ایک خوفناک فلم میں...  \n","...                                                 ...  \n","3779  جس سے نفرت کرتے ہو تاکہ اس کی نفرت کی بنا پر خ...  \n","6774  نظم● کرونا وائرس کرونا ہم نے تیرا کیا بگاڑا کر...  \n","7491  کمال ہے یہ تو مجھے بھی بلاک کر دیا اب چک کیا ہ...  \n","4488  کیوں نہ حیرت ہو کہ بغض و کینہ و رنج و ملالہم ک...  \n","864   عمران خان کے چہرے پر جو خوشی اور سکون غریبوں ک...  \n","\n","[3900 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-69a1e140-2073-496d-ba12-99b52531d6f2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>anger</th>\n","      <th>disgust</th>\n","      <th>fear</th>\n","      <th>sadness</th>\n","      <th>surprise</th>\n","      <th>happiness</th>\n","      <th>neutral</th>\n","      <th>Sentences</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4071</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>مینے سوچا بتادوں خوشی بانٹ دوں😂</td>\n","    </tr>\n","    <tr>\n","      <th>6073</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>میسر تجھے ہر خوشی ہوگی لیکن مجھے یاد کر کے تو ...</td>\n","    </tr>\n","    <tr>\n","      <th>3260</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>اقرار بریڈ پٹ کے بارے میں فنتاسیوں اندوز کرنے ...</td>\n","    </tr>\n","    <tr>\n","      <th>2589</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>اس کو کوئ ایک تکلیف ہو تو بتائیں حسد کی آگ میں...</td>\n","    </tr>\n","    <tr>\n","      <th>642</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>اس طرح ایک عظیم کتاب اس طرح ایک خوفناک فلم میں...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3779</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>جس سے نفرت کرتے ہو تاکہ اس کی نفرت کی بنا پر خ...</td>\n","    </tr>\n","    <tr>\n","      <th>6774</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>نظم● کرونا وائرس کرونا ہم نے تیرا کیا بگاڑا کر...</td>\n","    </tr>\n","    <tr>\n","      <th>7491</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>کمال ہے یہ تو مجھے بھی بلاک کر دیا اب چک کیا ہ...</td>\n","    </tr>\n","    <tr>\n","      <th>4488</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>کیوں نہ حیرت ہو کہ بغض و کینہ و رنج و ملالہم ک...</td>\n","    </tr>\n","    <tr>\n","      <th>864</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>عمران خان کے چہرے پر جو خوشی اور سکون غریبوں ک...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3900 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69a1e140-2073-496d-ba12-99b52531d6f2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-69a1e140-2073-496d-ba12-99b52531d6f2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-69a1e140-2073-496d-ba12-99b52531d6f2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":50}],"source":["train_dataset = CustomDataset(train_df,tokenizer,256)\n","val_dataset = CustomDataset(val_df,tokenizer,256)\n","\n","\n","train_df"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1661170729662,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"},"user_tz":-330},"id":"zePO1Zgbpprl","outputId":"ec0ac68a-4c17-4e28-873a-9a35fa2f7e3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["from torch.utils.data import TensorDataset , RandomSampler ,SequentialSampler ,DataLoader\n","#train_sampler = RandomSampler(train_dataset)\n","#val_sampler = SequentialSampler(val_dataset)\n","#test_sampler = SequentialSampler(test_data)\n","\n","\n","train_data_loader = torch.utils.data.DataLoader( train_dataset , shuffle = True  , batch_size = 16,num_workers =2 )\n","val_data_loader = torch.utils.data.DataLoader(val_dataset , shuffle =True , batch_size = 16,num_workers=2)\n","\n","print(device)\n"]},{"cell_type":"code","source":["import shutil\n","import sys\n","\n","def load_checkpoint(check_point_fpath,model,optimizer):\n","  checkpoint = torch.load(check_point_fpath)\n","  model.load_state_dict(checkpoint['step'])\n","  optimizer.load_state_dict(checkpoint['optimizer'])\n","  valid_loss_min = checkpoint['valid_loss_min']\n","\n","  return model,optimizer,checkpoint['epoch'],valid_loss_min\n","\n","\n","\n","def save_checkpoint(state , is_best ,checkpoint_path,best_model_path):\n","  f_path = checkpoint_path\n","  torch.save(state,f_path)\n","\n","  if is_best:\n","    best_fpath = best_model_path\n","    shutil.copyfile(f_path,best_fpath)"],"metadata":{"id":"SD-5aaprLPLS","executionInfo":{"status":"ok","timestamp":1661170729664,"user_tz":-330,"elapsed":18,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2919,"status":"ok","timestamp":1661170732566,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"},"user_tz":-330},"id":"UgQazWlxvwMK","outputId":"0edbd858-237d-4789-9ca0-1dbc3980195a"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["BERTClass(\n","  (bert_model): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (linear): Linear(in_features=768, out_features=7, bias=True)\n",")"]},"metadata":{},"execution_count":53}],"source":["from transformers import BertModel\n","\n","import torch.nn as nn\n","class BERTClass(torch.nn.Module):\n","  def __init__(self):\n","    super(BERTClass,self).__init__()\n","    self.bert_model = BertModel.from_pretrained('bert-base-multilingual-cased' , return_dict = True)\n","    self.dropout = nn.Dropout(0.3)\n","    self.linear = nn.Linear(768,7)\n","\n","\n","  def forward(self,input_ids,attention_mask,token_type_ids):\n","    output = self.bert_model(input_ids,attention_mask,token_type_ids)\n","    output_dropout = self.dropout(output.pooler_output)\n","    output = self.linear(output_dropout)\n","    return output \n","\n","model = BERTClass()\n","model.to(device)\n","\n"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"arXrXCINvv91","executionInfo":{"status":"ok","timestamp":1661170732567,"user_tz":-330,"elapsed":10,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"}}},"outputs":[],"source":["loss_model = nn.BCEWithLogitsLoss()\n","\n","optimizer = torch.optim.Adam(params = model.parameters() , lr = 2e-5 ,eps = 1e-8)\n","#print(* train_data_loader)\n","\n","def flattened_accuracy(pred,labels):\n","  pred_flat = np.argmax(pred,axis=1).flatten()\n","  labels_flat = labels.flatten()\n","\n","  return np.sum(pred_flat==labels_flat) / len(labels_flat)\n","\n","\n"]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6HI8AY7jvv54","outputId":"8cb39eb1-8717-4390-f723-1454f70a0f00","executionInfo":{"status":"ok","timestamp":1661176169980,"user_tz":-330,"elapsed":2563750,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"}}},"outputs":[{"output_type":"stream","name":"stdout","text":[" >>>>>>>>> Epoch 1 : Training..\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"]},{"output_type":"stream","name":"stdout","text":["Batch : 40 / 244\n","Batch : 80 / 244\n","Batch : 120 / 244\n","Batch : 160 / 244\n","Batch : 200 / 244\n","Batch : 240 / 244\n"," >>>>>>> Epoch 1 / 10: Training end >...< average loss: 0.06118870481894519 \n"," >>>>>>> Running validation \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:69: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"]},{"output_type":"stream","name":"stdout","text":["validation decreased inf --> 0 . Saving Model\n",">>>>>>Epoch 1 completed\n"," >>>>>>>>> Epoch 2 : Training..\n","Batch : 40 / 244\n","Batch : 80 / 244\n","Batch : 120 / 244\n","Batch : 160 / 244\n","Batch : 200 / 244\n","Batch : 240 / 244\n"," >>>>>>> Epoch 2 / 10: Training end >...< average loss: 0.05284176529461487 \n"," >>>>>>> Running validation \n",">>>>>>Epoch 2 completed\n"," >>>>>>>>> Epoch 3 : Training..\n","Batch : 40 / 244\n","Batch : 80 / 244\n","Batch : 120 / 244\n","Batch : 160 / 244\n","Batch : 200 / 244\n","Batch : 240 / 244\n"," >>>>>>> Epoch 3 / 10: Training end >...< average loss: 0.0469168302160306 \n"," >>>>>>> Running validation \n",">>>>>>Epoch 3 completed\n"," >>>>>>>>> Epoch 4 : Training..\n","Batch : 40 / 244\n","Batch : 80 / 244\n","Batch : 120 / 244\n","Batch : 160 / 244\n","Batch : 200 / 244\n","Batch : 240 / 244\n"," >>>>>>> Epoch 4 / 10: Training end >...< average loss: 0.04111420651172578 \n"," >>>>>>> Running validation \n",">>>>>>Epoch 4 completed\n"," >>>>>>>>> Epoch 5 : Training..\n","Batch : 40 / 244\n","Batch : 80 / 244\n","Batch : 120 / 244\n","Batch : 160 / 244\n","Batch : 200 / 244\n","Batch : 240 / 244\n"," >>>>>>> Epoch 5 / 10: Training end >...< average loss: 0.03702261623331025 \n"," >>>>>>> Running validation \n",">>>>>>Epoch 5 completed\n"," >>>>>>>>> Epoch 6 : Training..\n","Batch : 40 / 244\n","Batch : 80 / 244\n","Batch : 120 / 244\n","Batch : 160 / 244\n","Batch : 200 / 244\n","Batch : 240 / 244\n"," >>>>>>> Epoch 6 / 10: Training end >...< average loss: 0.033250142188483205 \n"," >>>>>>> Running validation \n",">>>>>>Epoch 6 completed\n"," >>>>>>>>> Epoch 7 : Training..\n","Batch : 40 / 244\n","Batch : 80 / 244\n","Batch : 120 / 244\n","Batch : 160 / 244\n","Batch : 200 / 244\n","Batch : 240 / 244\n"," >>>>>>> Epoch 7 / 10: Training end >...< average loss: 0.026375370900734465 \n"," >>>>>>> Running validation \n",">>>>>>Epoch 7 completed\n"," >>>>>>>>> Epoch 8 : Training..\n","Batch : 40 / 244\n","Batch : 80 / 244\n","Batch : 120 / 244\n","Batch : 160 / 244\n","Batch : 200 / 244\n","Batch : 240 / 244\n"," >>>>>>> Epoch 8 / 10: Training end >...< average loss: 0.02424942829062185 \n"," >>>>>>> Running validation \n",">>>>>>Epoch 8 completed\n"," >>>>>>>>> Epoch 9 : Training..\n","Batch : 40 / 244\n","Batch : 80 / 244\n","Batch : 120 / 244\n","Batch : 160 / 244\n","Batch : 200 / 244\n","Batch : 240 / 244\n"," >>>>>>> Epoch 9 / 10: Training end >...< average loss: 0.020707468751275944 \n"," >>>>>>> Running validation \n",">>>>>>Epoch 9 completed\n"," >>>>>>>>> Epoch 10 : Training..\n","Batch : 40 / 244\n","Batch : 80 / 244\n","Batch : 120 / 244\n","Batch : 160 / 244\n","Batch : 200 / 244\n","Batch : 240 / 244\n"," >>>>>>> Epoch 10 / 10: Training end >...< average loss: 0.01884599334629993 \n"," >>>>>>> Running validation \n",">>>>>>Epoch 10 completed\n"]}],"source":["import gc\n","gc.collect()\n","from transformers import get_linear_schedule_with_warmup\n","bestvalacc = 0\n","loss_val = []\n","def train_model (n_epoch , train_loader , val_loader ,model,optimizer ,checkpoint_path,best_model_path):\n","  val_loss_min  = np.inf\n","  for epoch in range(1,n_epoch+1):\n","    scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = len(train_data_loader)* n_epoch)\n","    train_loss = 0;\n","    valid_loss = 0;\n","    valid_acc = 0;\n","    nb_eval_steps = 0;\n","    model.train();\n","    print(\" >>>>>>>>> Epoch {} : Training..\".format(epoch))\n","\n","    for batch_idx, data in enumerate(train_loader):\n","      \n","      if batch_idx % 40 == 0  and not batch_idx == 0:\n","        print('Batch : {} / {}'.format(batch_idx,len(train_loader)))\n","\n","      ids = data['input_ids'].to(device , dtype = torch.long)\n","      mask = data['attention_mask'].to(device,dtype = torch.long)\n","      token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","      targets = data['targets'].to(device, dtype = torch.float)\n","\n","      outputs = model(ids, mask, token_type_ids)\n","\n","      \n","      loss = loss_model(outputs,targets)\n","      optimizer.zero_grad()\n","      loss.backward()      \n","      train_loss += loss.item()\n","      torch.nn.utils.clip_grad_norm(model.parameters(),1.0)\n","      optimizer.step()\n","      scheduler.step();\n","\n","    avg_train_loss =  train_loss / len(train_data_loader)\n","    loss_val.append(avg_train_loss)\n","\n","    print(\" >>>>>>> Epoch {} / {}: Training end >...< average loss: {} \".format(epoch , n_epoch, avg_train_loss))\n","\n","    print(\" >>>>>>> Running validation \")\n","\n","    model.eval();\n","\n","    val_loss = []\n","    val_accuracy = []\n","    bestvalacc =0;\n","    for data in val_loader:\n","      in_id = data['input_ids'].to(device,dtype = torch.long)\n","      at_mask = data['attention_mask'].to(device,dtype = torch.long)\n","      t_t_id = data['token_type_ids'].to(device,dtype = torch.long)\n","      targets = data['targets'].to(device,dtype = torch.float)\n","\n","      with torch.no_grad():\n","        outputs = model(in_id,at_mask,t_t_id)\n","      logits = outputs[0]\n","\n","      loss = loss_model(outputs,targets)\n","      val_loss.append(loss.item())\n","    \n","\n","      logits = logits.detach().cpu().numpy()\n","      label_ids = targets.cpu().numpy()\n","\n","      temp_accuracy  = np.sum(logits.flatten() == label_ids.flatten()) / len(label_ids.flatten()) \n","      val_accuracy.append(temp_accuracy)\n","\n","\n","\n","    val_loss = np.mean(val_loss)\n","    val_accuracy = np.mean(val_accuracy)\n","    checkpoint_dict = {\n","        'epoch' : epoch,\n","        'valid_loss_min': val_loss,\n","        'state_dict': model.state_dict(),\n","        'optimizer': optimizer.state_dict()\n","    }\n","\n","    save_checkpoint(checkpoint_dict,False,checkpoint_path , best_model_path )\n","    if val_loss < val_loss_min:\n","      save_checkpoint(checkpoint_dict, True , checkpoint_path,best_model_path)\n","      print(\"validation decreased {} --> {} . Saving Model\".format(val_loss_min,valid_loss))\n","      val_loss_min = valid_loss\n","\n","\n","    print(\">>>>>>Epoch {} completed\".format(epoch)) \n","  return model \n","\n","\n","  \n","\n","\n","ckpt_path = \"/content/drive/MyDrive/Urdu_hate/curr_ckpt\"\n","best_model_path = \"/content/drive/MyDrive/Urdu_hate/best_model_path.pt\"\n","trained_model = train_model (10 , train_data_loader , val_data_loader ,model,optimizer,ckpt_path,best_model_path)\n","\n","\n","\n","\n","    "]},{"cell_type":"code","execution_count":61,"metadata":{"id":"i59lilFY301T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661176169982,"user_tz":-330,"elapsed":21,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"}},"outputId":"76728627-4bfb-41fd-86da-8c08519fbaf2"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training Complete\n"]}],"source":["print(\"\")\n","print(\"Training Complete\")"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"K7MA3E1E4BU3","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1661176170990,"user_tz":-330,"elapsed":1019,"user":{"displayName":"Anik Basu Bhaumik","userId":"07595284515233622357"}},"outputId":"e7c1bd43-38c9-445a-bcb4-3dfb597b5046"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["import matplotlib.pyplot as plt\n","\n","\n","plt.plot(loss_val,'b-o')\n","plt.title(\"Training loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.show()"]},{"cell_type":"code","source":["test_Data = pd.read_csv(\"/content/drive/MyDrive/Urdu_hate/test_set_taskA_unlabelled - test_set_Fire2022_unlabelled\")\n","\n","model.eval()\n","\n","predictions , true_labels = [] , []\n","\n","test_dataset = CustomDataset(test_Data,tokenizer,256)\n","\n","test_data_loader = torch.utils.data.DataLoader( test_dataset , shuffle = True  , batch_size = 16,num_workers = 2 )\n","\n","\n","for data in test_data_loader:\n","  in_id = data['input_ids'].to(device,dtype = torch.long)\n","  at_mask = data['attention_mask'].to(device,dtype = torch.long)\n","  t_t_id = data['token_type_ids'].to(device,dtype = torch.long)\n","  \n","\n","\n","  with torch.no_grad():\n","    outputs = model(in_id,at_mask,t_t_id)\n","  logits = outputs[0]\n","\n","  logits = logits.detach().cpu().numpy()\n","  predictions.append(logits)\n","\n","print('DONE')\n"],"metadata":{"id":"bUVkUfhIqbVN"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"Urdu-Hate-Alert.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1o-o1esr1b9DHE0I7zf-qpKeV3G981l8B","authorship_tag":"ABX9TyMUwnoSe6/f6zFeykw07K5y"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}